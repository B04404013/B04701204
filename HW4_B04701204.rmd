---
title: "HW4_B04701204"
author: "B04701204"
date: "2017年10月21日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


##題目：比較美國前總統歐巴馬於總統任期前後的臉抒發文內容

以文字雲呈現美國前總統歐巴馬於總統任期前後的臉抒發文內容，分成任職前(Pre-Presidency)、第一任期(First Term)、第二任期(Second Term)、卸任後(Post-Presidency)。

### 套件安裝 - 抓臉書資料
```{r install, eval=FALSE}
install.packages("devtools")
library(devtools)
install_version("httr", version = "1.2.0", repos = "http://cran.us.r-project.org")
install.packages("rjson")
install.packages("httpuv")
install_github("pablobarbera/Rfacebook/Rfacebook")
```

### 套件執行 - 抓臉書資料
```{r library}
library(devtools)
library(httr)
library(rjson)
library(httpuv)
require(Rfacebook)
```

### 網路爬蟲

透過 fbOAuth function 取得 access token，再透過 token 取得歐巴馬於四段時期的發文。為減省作業，因此取百篇內的貼文。     

# 後來發現因為之前取得過token並存取後，直接用load就沒有問題了，不知道這是為什麼？

```{r crawler}
# generate a 'long-lived' token using the fbOAuth function
#fb_oauth <- fbOAuth(app_id="1569896156438201", app_secret="8b593e1538dc2aae0ca986806bdd4093",extended_permissions = TRUE)

# save fb_oauth for future use
#save(fb_oauth, file="fb_oauth")
load("fb_oauth")

# set token
token = fb_oauth

# extract data from page
page_PreElect <- getPage("barackobama", token, n=100, since='2007/02/10', until ='2008/11/04')
page_First <- getPage("barackobama", token, n=100, since='2009/01/20', until='2013/01/21')
page_Second <- getPage("barackobama", token, n=100, since='2013/01/21', until='2017/01/20')
page_Depart <- getPage("barackobama", token, n=100, since='2017/01/20', until='2017/10/21')
```

### 套件安裝 - 製作文字雲
```{r install2, eval=FALSE}
install.packages('rvest')
install.packages('NLP')
install.packages('tm')
install.packages('stringr')
install.packages('wordcloud')
install.packages('RColorBrewer')
```

### 套件執行 - 製作文字雲
```{r library2}
library(rvest)
library(NLP)
require(tm)
library(stringr)
library(wordcloud)
require(RColorBrewer)
```

### 文本清理

先將四段時期的發文個別合併成單一 string，再合併成 corpus。

```{r cleaning1}
#Data-Preprocessing: combine posts as separate strings
page_PreElect_post <- paste(page_PreElect$message, collapse = " ")
page_First_post <- paste(page_First$message, collapse = " ")
page_Second_post <- paste(page_Second$message, collapse = " ")
page_Depart_post <- paste(page_Depart$message, collapse = " ")

#Data-Preprocessing: combine as corpus
corpus <- c(page_PreElect_post, page_First_post, page_Second_post, page_Depart_post)
```

清理 corpus，其中排除影響力過大且分析意義較低的自，比如網址連結中的"http"、總統名字"barack""obama"、職稱"president"。

```{r cleaning2}
#Data-Preprocessing: removing non-words
corpus2 <- gsub("\\W"," ",corpus)

#Data-Preprocessing: removing digits
corpus2 <- gsub("\\d"," ",corpus2)

#Data-Preprocessing: changing all to lower case
corpus2 <- tolower(corpus2)

#Data-Preprocessing: removing stopwords
corpus2 <- removeWords(corpus2,stopwords())

#Data-Preprocessing: removing single letters
corpus2 <- gsub("\\b[A-z]\\b{1}"," ",corpus2)

#Data-Preprocessing: removing whitespaces
corpus2 <- stripWhitespace(corpus2)

#Data-Preprocessing: removing irrelevant words
corpus2 <- gsub("http"," ",corpus2)
corpus2 <- gsub("barack"," ",corpus2)
corpus2 <- gsub("obama"," ",corpus2)
corpus2 <- gsub("president"," ",corpus2)
```

### 文字雲

由文字雲可以看出歐巴馬於四段時的發文內容趨勢，從中觀察各時期關注的議題有何差異。

1. 任職前(Pre-Presidency)：

2. 第一任期(First Term)：

3. 第二任期(Second Term)：

4. 卸任後(Post-Presidency)：

```{r wordcloud}
#Create Comparison Word Cloud: create corpus vector
corpus3 <- Corpus(VectorSource(corpus2))

#Create Comparison Word Cloud: create Term Document Matrix
tdm <- TermDocumentMatrix(corpus3)
m <- as.matrix(tdm)

#Create Comparison Word Cloud: rename columns of tdm
colnames(m) <- c("Pre-Presidency", "First Term", "Second Term", "Post-Presidency")

#Create Comparison Word Cloud
comparison.cloud(m, max.words=200,scale=c(2,.5),random.order=FALSE,title.size=1.5)
```